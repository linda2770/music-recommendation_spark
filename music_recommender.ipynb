{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommender System using Apache Spark and Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the three datasets into RDDs and name them `artistData`, `artistAlias`, and `userArtistData`. View the README, or the files themselves, to see how this data is formated. I only some the sample dataset for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(s, delimeters=\" \", to_int=None):\n",
    "    s = s.split(delimeters)\n",
    "    if to_int:\n",
    "        return tuple([int(s[i]) if i in to_int else s[i] for i in range(len(s))])\n",
    "    return tuple(s)\n",
    "artistData = sc.textFile(\"artist_data_small.txt\").map(lambda x: parser(x,'\\t',[0]))\n",
    "artistAlias = sc.textFile(\"artist_alias_small.txt\").map(lambda x: parser(x,'\\t', [0,1]))\n",
    "artistAliasMap = artistAlias.collectAsMap()\n",
    "userArtistData = sc.textFile(\"user_artist_data_small.txt\").map(lambda x: parser(x,' ',[0,1,2]))\n",
    "userArtistData = userArtistData.map(lambda x: (x[0], artistAliasMap.get(x[1], x[1]), x[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1059637 has a total play count of 674412 and a mean play count of 1878.\n",
      "User 2064012 has a total play count of 548427 and a mean play count of 9455.\n",
      "User 2069337 has a total play count of 393515 and a mean play count of 1519.\n"
     ]
    }
   ],
   "source": [
    "def summary(user_id):\n",
    "    play_list = userArtistData.map(lambda x: (x[0], (x[1], x[2]))).lookup(user_id)\n",
    "    total = sum(x[1] for x in play_list)\n",
    "    print \"User %s has a total play count of %s and a mean play count of %s.\" % (user_id, total, total/len(play_list),)\n",
    "summary(1059637)\n",
    "summary(2064012)\n",
    "summary(2069337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Splitting Data for Testing\n",
    "\n",
    "\n",
    "* A training set, `trainData`, that will be used to train the model. This set should constitute 40% of the data.\n",
    "* A validation set, `validationData`, used to perform parameter tuning. This set should constitute 40% of the data.\n",
    "* A test set, `testData`, used for a final evaluation of the model. This set should constitute 20% of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1059637, 1000049, 1), (1059637, 1000056, 1), (1059637, 1000113, 5)]\n",
      "[(1059637, 1000010, 238), (1059637, 1000062, 11), (1059637, 1000112, 423)]\n",
      "[(1059637, 1000094, 1), (1059637, 1000130, 19129), (1059637, 1000139, 4)]\n",
      "19817\n",
      "19633\n",
      "10031\n"
     ]
    }
   ],
   "source": [
    "trainingData, validationData, testData = userArtistData.randomSplit([40,40,20], 13)\n",
    "trainingData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()\n",
    "print trainingData.take(3)\n",
    "print validationData.take(3)\n",
    "print testData.take(3)\n",
    "print trainingData.count()\n",
    "print validationData.count()\n",
    "print testData.count()\n",
    "# validationSet.lookup(1073421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recommender Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "def cal_score(predict, actual):\n",
    "    if len(actual) < len(predict):\n",
    "#         print \"here\"\n",
    "        predict = predict[0:len(actual)]\n",
    "    return len(list(set(predict) & set(actual)))*1.0/len(actual)\n",
    "\n",
    "def modelEval(model, dataset):\n",
    "    # Find the list of all artists in the whole data set\n",
    "    all_artists = userArtistData.map(lambda x: x[1]).distinct().collect()\n",
    "    # Find the users in the input dataset\n",
    "    test_user = dataset.map(lambda p: p[0]).distinct().collect()\n",
    "    # Find the artists each user listened to in the training set and generate the test data\n",
    "    global trainingData\n",
    "    testdata = trainingData.filter(lambda x: x[0] in test_user).map(lambda x: (x[0], x[1])).groupByKey()\n",
    "    testdata = testdata.map(lambda x: (x[0], list(x[1])))\n",
    "    testdata = testdata.flatMap(lambda x: [(x[0],a) for a in all_artists if a not in x[1]])\n",
    "    # Find the artists each user listened to in the input dataset\n",
    "    testdata_actual = dataset.map(lambda x: (x[0], x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).collectAsMap()\n",
    "    predictions = model.predictAll(testdata).map(lambda x: (x[0], (x[1], x[2])))\n",
    "    predictions = predictions.groupByKey().map(lambda x: (x[0], sorted(list(x[1]), key=lambda y: y[1], reverse=True)))\n",
    "    predictions = predictions.map(lambda x: (x[0], cal_score([y[0] for y in x[1]], testdata_actual[x[0]])))\n",
    "    return predictions.map(lambda x:x[1]).reduce(lambda x, y: x+ y) * 1.0 / len(test_user)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score for rank 2 is 0.0884421125678\n",
      "The model score for rank 10 is 0.0980943620399\n",
      "The model score for rank 20 is 0.0902867925232\n"
     ]
    }
   ],
   "source": [
    "training = trainingData.map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2])))\n",
    "for r in [2, 10, 20]:\n",
    "    model = ALS.trainImplicit(training, rank = r, seed=345)\n",
    "    print \"The model score for rank %s is %s\" % (r, modelEval(model, validationData),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0571818264943\n"
     ]
    }
   ],
   "source": [
    "bestModel = ALS.trainImplicit(training, rank=10, seed=345)\n",
    "print modelEval(bestModel, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Some Artist Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 0: Taking Back Sunday\n",
      "Artist 1: Brand New\n",
      "Artist 2: Death Cab for Cutie\n",
      "Artist 3: Elliott Smith\n",
      "Artist 4: Jimmy Eat World\n"
     ]
    }
   ],
   "source": [
    "recommended = map(lambda x: x.product, bestModel.recommendProducts(1059637, 5))\n",
    "for i, artist in enumerate(recommended):\n",
    "    print \"Artist %s: %s\" % (i, artistData.lookup(artist)[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
